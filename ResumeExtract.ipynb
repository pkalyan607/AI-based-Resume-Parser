{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "lgJ4OqKE7_ZR"
      },
      "outputs": [],
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import os\n",
        "\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pdfminer.six\n",
        "!pip install nltk\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('words')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uiuXj3Bj8Sot",
        "outputId": "41741610-3508-4a28-e7c2-ea1ce3ff8c45"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pdfminer.six in /usr/local/lib/python3.10/dist-packages (20221105)\n",
            "Requirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six) (3.3.0)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six) (41.0.4)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=36.0.0->pdfminer.six) (1.16.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six) (2.21)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pdfminer.high_level import extract_text\n",
        "import nltk\n",
        "import re\n",
        "import subprocess\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fOuevacb8Sqw",
        "outputId": "d25fc915-c8dd-425b-cdf2-8f84c07cb1da"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json"
      ],
      "metadata": {
        "id": "AYaSaGeS8Ss3"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Name"
      ],
      "metadata": {
        "id": "5drXiMDH8uOF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_text_from_pdf(pdf_path):\n",
        "    text = extract_text(pdf_path)\n",
        "    return text\n",
        "\n",
        "txt = extract_text_from_pdf(\"/content/PavanKalyan_Resume4_.pdf\")"
      ],
      "metadata": {
        "id": "TqRQgehO8Sua"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(txt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FHzhR7sF8SzW",
        "outputId": "7960dee4-d576-43f8-a5bc-88228a84c5cd"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PALLA PAVAN KALYAN\n",
            "+91-6302614138 ⋄ Kadapa, Andhra Pradesh ⋄ pallapavankalyan607@gmail.com\n",
            "\n",
            "github.com/pkalyan607\n",
            "\n",
            "linkedin.com/pavan-kalyan-palla\n",
            "\n",
            "EDUCATION\n",
            "\n",
            "Bachelor of Technology, Indian Institute of Information Technology Kottayam, CGPA: 8.12\n",
            "\n",
            "Expected 2024\n",
            "\n",
            "Courses: Data Structures and Algorithms, Operating Systems, Artificial Intelligence, Machine Learning, Computer\n",
            "Networks, DBMS and Data Mining.\n",
            "\n",
            "Board of Intermediate Education, Narayana Junior College, CGPA: 9.94\n",
            "\n",
            "CBSE Class 10, Jawahar Navodaya Vidyalaya Kadapa, Percentage: 91.6\n",
            "\n",
            "2018 - 2020\n",
            "\n",
            "2018\n",
            "\n",
            "SKILLS\n",
            "\n",
            "Languages: Python, C, C++, SQL, HTML, CSS, JavaScript, R\n",
            "Frameworks: Scikit-Learn, TensorFlow, Keras, OpenCV, NLP, Google Cloud Platform\n",
            "Tools:\n",
            "Cloud:\n",
            "Soft Skills:\n",
            "\n",
            "MySQL, Docker\n",
            "GCP, AWS\n",
            "Leadership, Problem Solving, Good Communication, Motivation and Team Work.\n",
            "\n",
            "INTERNSHIP EXPERIENCE\n",
            "\n",
            "Feynn Labs Services - Machine Learning Intern\n",
            "\n",
            "May 2023 - July 2023\n",
            "\n",
            "Worked on the following projects\n",
            "\n",
            "1.Developed and prototyped an AI-driven Agricultural Yield Prediction system, leveraging machine learning algo-\n",
            "rithms and historical crop data to forecast crop yields accurately.\n",
            "\n",
            "2.Revolutionized Electric Vehicle sector with ML-driven Market Segmentation, fueling data-centric innovation and\n",
            "marketing.\n",
            "\n",
            "3.Developed NLP-based Resume Parsing system for efficient candidate selection, enhancing business productivity and\n",
            "profitability.\n",
            "\n",
            "PROJECTS\n",
            "\n",
            "*Smart Restaurant: Developed a web-based Smart Restaurant Menu Ordering System using HTML, CSS, JavaScript,\n",
            "and Django, enhancing the customer dining experience and optimizing restaurant operations. Aug 2022 - Oct 2022\n",
            "\n",
            "*Passport Automation System: Developed an online Passport Automation System, optimizing and automating\n",
            "March 2022 - May 2022\n",
            "the passport application process for increased efficiency and user accessibility.\n",
            "\n",
            "EXTRA-CURRICULAR ACTIVITIES\n",
            "\n",
            "• Actively participating in Athletics Events like Running, Long Jump, High Jump.\n",
            "\n",
            "• As a Scout, experience in practical outdoor activities, including camping, woodcraft, aquatics, hiking, and sports.\n",
            "\n",
            "ACHIEVEMENTS\n",
            "\n",
            "• Received Rajya Puraskar Certificate for Scouts.\n",
            "\n",
            "• Got 2nd in High Jump Regional level Competition.\n",
            "\n",
            "• Received Gold Medal in district level Yoga Competion.\n",
            "\n",
            "\f\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_names(txt):\n",
        "    person_names = []\n",
        "\n",
        "    for sent in nltk.sent_tokenize(txt):\n",
        "        for chunk in nltk.ne_chunk(nltk.pos_tag(nltk.word_tokenize(sent))):\n",
        "            if hasattr(chunk, 'label') and chunk.label() == 'PERSON':\n",
        "                person_names.append(\n",
        "                    ' '.join(chunk_leave[0] for chunk_leave in chunk.leaves())\n",
        "                )\n",
        "\n",
        "    return person_names"
      ],
      "metadata": {
        "id": "aynhB3sl9ysQ"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "names = extract_names(txt)"
      ],
      "metadata": {
        "id": "JeGYwbgy9yuh"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PUnJcxLM9ywM",
        "outputId": "d87b5310-0533-496f-cab9-3136adaef779"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Andhra Pradesh',\n",
              " 'Data Structures',\n",
              " 'Systems',\n",
              " 'Machine Learning',\n",
              " 'Data Mining',\n",
              " 'Board',\n",
              " 'Narayana Junior College',\n",
              " 'Jawahar Navodaya Vidyalaya Kadapa',\n",
              " 'Percentage',\n",
              " 'Python',\n",
              " 'Keras',\n",
              " 'Google Cloud Platform Tools',\n",
              " 'Docker GCP',\n",
              " 'Problem Solving',\n",
              " 'Good Communication',\n",
              " 'Team Work',\n",
              " 'Machine Learning Intern',\n",
              " 'Yield',\n",
              " 'Market Segmentation',\n",
              " 'Resume Parsing',\n",
              " 'Smart Restaurant',\n",
              " 'Smart Restaurant Menu Ordering System',\n",
              " 'High Jump',\n",
              " 'Scouts',\n",
              " 'Received Gold Medal',\n",
              " 'Yoga Competion']"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Phone Number"
      ],
      "metadata": {
        "id": "DoLoMfmN_CsG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PHONE_REG_IND = re.compile(r'[\\+\\(]?[1-9][0-9 .\\-\\(\\)]{8,}[0-9]')\n",
        "\n",
        "PHONE_REG_USA = re.compile(r'/^\\(?(\\d{3})\\)?[-]?(\\d{3})[-]?(\\d{4})$/')"
      ],
      "metadata": {
        "id": "nUrn__-R9y0V"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_phone_number(resume_text):\n",
        "    phone = re.findall(PHONE_REG_IND, resume_text)\n",
        "\n",
        "    if phone:\n",
        "        number = ''.join(phone[0])\n",
        "\n",
        "        if resume_text.find(number) >= 0 and len(number) < 16:\n",
        "            return number\n",
        "    return None\n",
        "\n",
        "phone_number_ind = extract_phone_number(txt)\n",
        "print(phone_number_ind)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "reYAfZrA-QdM",
        "outputId": "55db312a-89c5-4ef2-b58f-a240caf8d4f8"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+91-6302614138\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_phone_number(resume_text):\n",
        "    phone = re.findall(PHONE_REG_USA, resume_text)\n",
        "\n",
        "    if phone:\n",
        "        if resume_text.find(phone) >= 0:\n",
        "            return phone\n",
        "    return None\n",
        "\n",
        "phone_number_usa = extract_phone_number(txt)\n",
        "print(phone_number_usa)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iR7k0EqJ_P15",
        "outputId": "8c213377-3778-45b6-db0b-909e675e1da6"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Email Id"
      ],
      "metadata": {
        "id": "uaeFvio7_SOY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EMAIL_REG = re.compile(r'[a-z0-9\\.\\-+_]+@[a-z0-9\\.\\-+_]+\\.[a-z]+')\n"
      ],
      "metadata": {
        "id": "dsXWQVF9_Wfj"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_emails(resume_text):\n",
        "    return re.findall(EMAIL_REG, resume_text)"
      ],
      "metadata": {
        "id": "9oi8lNNW_as4"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emails = extract_emails(txt)\n",
        "\n",
        "if emails:\n",
        "    print(emails)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ewf5Fxpk_amD",
        "outputId": "b6e0cbb3-6d07-42ae-ca12-73468ff308af"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['pallapavankalyan607@gmail.com']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Information Dictionary"
      ],
      "metadata": {
        "id": "lEIqi-SV_hnl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "general_dict={ 'Name' : name_candidate.upper(),\n",
        "              'email' : emails ,\n",
        "              'contact' : phone_number_ind\n",
        "\n",
        "}\n",
        "\n",
        "general_dict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Te1UypnR_gSa",
        "outputId": "34a34674-f25d-48e4-e2f1-872f2342461e"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Name': 'ANDHRA PRADESH',\n",
              " 'email': ['pallapavankalyan607@gmail.com'],\n",
              " 'contact': '+91-6302614138'}"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Skills"
      ],
      "metadata": {
        "id": "3QpJZm7I_tsv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_skills(txt):\n",
        "    pattern = r\"SKILLS:(.*?)Experience:\"\n",
        "    matches = re.search(pattern, txt, re.DOTALL)\n",
        "\n",
        "    if matches:\n",
        "        skills_section = matches.group(1)\n",
        "        SKILLS = re.findall(r\"\\b\\w+\\b\", skills_section)\n",
        "        return SKILLS\n",
        "\n",
        "    return []"
      ],
      "metadata": {
        "id": "Tcmjoj96_tHV"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SKILLS = extract_skills(txt)\n",
        "print(SKILLS)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J3Dzo3HU_tDb",
        "outputId": "a2a3a6c9-8a6e-4eb3-9dee-10024a7f65b4"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6oWw2LG6_tBS"
      },
      "execution_count": 40,
      "outputs": []
    }
  ]
}